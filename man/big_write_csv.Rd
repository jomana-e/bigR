% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/big_write_csv.R
\name{big_write_csv}
\alias{big_write_csv}
\title{Write a large dataset to a CSV efficiently}
\usage{
big_write_csv(data, file, backend = "auto", chunk_size = NULL)
}
\arguments{
\item{data}{A dataframe to write}

\item{file}{Path to save the file}

\item{backend}{Choose backend: "auto", "data.table", "arrow", "duckdb"}

\item{chunk_size}{Optional chunk size for writing in parts}
}
\description{
Write a large dataset to a CSV efficiently
}
\examples{
\dontrun{
# Basic usage with automatic backend selection
big_write_csv(data, "output.csv")

# Using data.table for fast writing
big_write_csv(data, "output.csv", backend = "data.table")

# Writing large dataset in chunks
big_write_csv(large_data, "output.csv", chunk_size = 10000)

# Writing processed data
data \%>\%
  big_filter(value > 0) \%>\%
  big_mutate(log_value = log(value)) \%>\%
  big_write_csv("processed_data.csv")

# Using Arrow backend for compression
big_write_csv(data, "compressed.csv.gz", backend = "arrow")
}
}
